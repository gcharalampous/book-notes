# Thinking, Fast and Slow

## Author: Daniel Kahneman

---

## Table of Contents

- [Thinking, Fast and Slow](#thinking-fast-and-slow)
  - [Author: Daniel Kahneman](#author-daniel-kahneman)
  - [Table of Contents](#table-of-contents)
  - [Part-II: Heuristics and Biases](#part-ii-heuristics-and-biases)
    - [Summary](#summary)
      - [Ch 10: The Law of Small Numbers](#ch-10-the-law-of-small-numbers)
      - [Ch 11: Anchors](#ch-11-anchors)
      - [Ch 12: The Science of Availability](#ch-12-the-science-of-availability)
      - [Ch 13: Availability, Emotion, and Risk](#ch-13-availability-emotion-and-risk)
      - [Ch 14: Availability, Emotion, and Risk](#ch-14-availability-emotion-and-risk)
      - [Ch 15: Linda: Less is More](#ch-15-linda-less-is-more)
    - [Reflections](#reflections)
  - [Key Takeaways](#key-takeaways)
  - [Favorite Quotes](#favorite-quotes)
  - [Additional Notes](#additional-notes)

---


## Part-II: Heuristics and Biases

### Summary

[Write a brief summary of the chapter here]

#### Ch 10: The Law of Small Numbers

- System 1 is highly adept in one form of thinking, automatically and effortlessly identifying causal connections between events, sometimes even when the connection is spurious.
- Large samples are more precise than small samples. Small samples yield extreme results more often than large samples do.
- A machine for jumping to conclusions will act as if it believed in the law of small numbers and produce a representation of reality that makes too much sense.
- The exaggerated faith in small samples is one example of a broader illusion: we focus more on the content of messages than their reliability, leading to a simpler and more coherent view of the world than the data justify. Jumping to conclusions is safer in our imagination than in reality.
- Statistics produce many observations that seem to beg for causal explanations but do not support them. Many facts are due to chance, including sampling accidents. Causal explanations of chance events are inevitably wrong.


#### Ch 11: Anchors

- Anchoring effects arise from two mechanisms: one through deliberate adjustment (System 2) and the other via priming (System 1).
- Adjust-and-anchor heuristic for estimating uncertain quantities: start with an anchor number, assess if it’s too high or low, and adjust your estimate accordingly. However, adjustments often stop prematurely when people feel uncertain about moving further.
- People who shake their heads in response to an anchor tend to move further away from it, while those who nod their heads exhibit stronger anchoring effects.
- People adjust less from the anchor when their mental resources are depleted, such as when their memory is loaded or when they are slightly intoxicated.
- Adjustment is a deliberate and conscious activity, but in most cases of anchoring there is no corresponding subjective experience.
- System 1 processes sentences by attempting to make them true, leading to the selective activation of compatible thoughts. This can result in systematic errors that make us gullible and overly confident in our beliefs.
- System 1 tries its best to construct a world in which the anchor is the true number. 
- Both suggestion and anchoring are driven by the automatic operations of System 1. 
- Deliberately "thinking the opposite" can be an effective defense against anchoring effects, as it counters the biased thought processes that contribute to them.
- System 2 relies on data retrieved by System 1, making it susceptible to biases from anchors that facilitate information retrieval. Additionally, System 2 lacks control over these effects and is unaware of them.

#### Ch 12: The Science of Availability

- We defined the availability heuristic as the process of judging frequency by “the ease with which instances come to mind.”
- Sources of bias
  - A salient event that attracts your attention will be easily retrieved from memory.
  - A dramatic event temporarily increases the availability of its category. 
  - Personal experiences, pictures, and vivid examples are more available than incidents that happened to others, or mere words, or statistics.
- The ease of recalling assertiveness instances changes during the task: starts easy, becomes harder. The expected gradual fluency drop between six and twelve instances is steeper than anticipated.
- System 1 sets expectations and is surprised when they are violated, retrieving possible causes from recent surprises. System 2 can reset System 1's expectations, making surprising events seem normal.
- People who are personally involved in the judgment are more likely to consider the number of instances they retrieve from memory and less likely to go by fluency.
- The conclusion is that the ease with which instances come to mind is a System 1 heuristic, which is replaced by a focus on content when System 2 is more engaged.
- Evidence shows that people guided by System 1 are more susceptible to availability biases than those in a state of higher vigilance.

#### Ch 13: Availability, Emotion, and Risk
- The world in our heads is not an exact replica of reality; our expectations about event frequency are distorted by the prevalence and emotional intensity of the messages we receive.
- They observed that the ease with which ideas of various risks come to mind and the emotional reactions to these risks are inextricably linked.
- People form opinions and make choices based on their feelings and basic tendencies to approach or avoid, often without realizing it. The affect heuristic is an instance of substitution, where the answer to an easy question (How do I feel about it?) serves as an answer to a harder question (What do I think about it?).
- People’s emotional evaluations of outcomes, along with the bodily states and approach or avoidance tendencies associated with them, play a central role in guiding decision-making.
- All heuristics are equal, but availability is more equal than the others. This expanded notion of the heuristic suggests that availability affects judgments beyond frequency. Specifically, the importance of an idea is often judged by how fluently (and emotionally charged) it comes to mind.
- A basic limitation of our mind in dealing with small risks is that we either ignore them altogether or give them far too much weight—nothing in between.

#### Ch 14: Availability, Emotion, and Risk
- The similarity of an individual to the stereotype of a group is unaffected by the size of the group. 
- When an incorrect intuitive judgment is made, both System 1 and System 2 are responsible. System 1 suggested the incorrect intuition, and System 2 endorsed it. System 2's failure can be due to either ignorance or laziness. 
- System-2 'knows' the base-rates are relevant even when they are not explicitly mentioned, but applies that knowledge only when it invests special effort in the task.
- Ignorance occurs when people ignore base rates, believing them irrelevant with individual information. Laziness happens when they aren't focused. If frowning affects judgment, laziness is the likely cause of base-rate neglect.
- When in doubt about evidence quality, keep your probability judgments close to the base rate. This requires significant self-monitoring and self-control.
- Two key ideas about Bayesian reasoning and common errors: 
  - Base rates matter, even with specific evidence.
  - Intuitive impressions of evidence diagnosticity are often exaggerated.
- The essential keys to disciplined Bayesian reasoning can be simply summarized:
  - Anchor your judgment of the probability of an outcome on a plausible base rate.
  - Question the diagnosticity of your evidence.


#### Ch 15: Linda: Less is More

- The conjunction fallacy occurs when people assume that the combination of two events is more likely than just one event alone, even though it's statistically less probable. This often happens due to representativeness heuristics, where specific details make the combined scenario seem more plausible.
- Coherent stories often appear more plausible because they align with our expectations and intuitions, but that doesn't make them more probable. Plausibility can mislead people into confusing it with probability, especially when the narrative fits well together, even if it's statistically unlikely.
- The absurdity of the less-is-more pattern was clear in Hsee’s dinnerware study but unnoticed by thousands who committed the conjunction fallacy in the Linda problem. The plausibility of the conjunction was enough for System 2 endorsement.
 


### Reflections

- [Your personal thoughts or reflections on the chapter]

---


## Key Takeaways

- [Key takeaway 1]
- [Key takeaway 2]
- [Key takeaway 3]

---

## Favorite Quotes

- "I plan to keep the results of the experiment secret until we have a sufficiently large sample. Otherwise we will face pressure to reach a conclusion prematurely." - Chapter 10
- “Our aim in the negotiation is to get them anchored on this number.” - Chapter 11
- This is an availability cascade: a nonevent that is inflated by the media and the public until it fills our TV screens and becomes all anyone is talking about. - Chappter 13
- “They keep making the same mistake: predicting rare events from weak evidence. When the evidence is weak, one should stick with the base rates.” - Chapter 14

---

## Additional Notes

[Write any additional notes or thoughts here]
